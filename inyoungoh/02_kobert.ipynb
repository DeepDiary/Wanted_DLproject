{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>아 진짜! 사무실에서 피지 말라니깐! 간접흡연이 얼마나 안좋은데!</td>\n",
       "      <td>분노</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>그럼 직접흡연하는 난 얼마나 안좋겠니? 안그래? 보면 꼭... 지 생각만 하고.</td>\n",
       "      <td>혐오</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>손님 왔어요.</td>\n",
       "      <td>중립</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>손님? 누구?</td>\n",
       "      <td>중립</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>몰라요. 팀장님 친구래요.</td>\n",
       "      <td>중립</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94189</th>\n",
       "      <td>솔직히 예보 제대로 못하는 데 세금이라도 아끼게 그냥 폐지해라..</td>\n",
       "      <td>혐오</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94190</th>\n",
       "      <td>재미가 없으니 망하지</td>\n",
       "      <td>혐오</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94191</th>\n",
       "      <td>공장 도시락 비우생적임 아르바이트했는데 화장실가성 손도 않씯고 재료 담고 바닥 떨어...</td>\n",
       "      <td>혐오</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94192</th>\n",
       "      <td>코딱지 만한 나라에서 지들끼리 피터지게 싸우는 센징 클래스 ㅉㅉㅉ</td>\n",
       "      <td>혐오</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94193</th>\n",
       "      <td>와이프도 그렇고 댓글 다 볼텐데 이휘재 좀 하차 하라고 전해주세요</td>\n",
       "      <td>혐오</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94194 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Sentence Emotion\n",
       "0                   아 진짜! 사무실에서 피지 말라니깐! 간접흡연이 얼마나 안좋은데!      분노\n",
       "1           그럼 직접흡연하는 난 얼마나 안좋겠니? 안그래? 보면 꼭... 지 생각만 하고.      혐오\n",
       "2                                                손님 왔어요.      중립\n",
       "3                                                손님? 누구?      중립\n",
       "4                                         몰라요. 팀장님 친구래요.      중립\n",
       "...                                                  ...     ...\n",
       "94189               솔직히 예보 제대로 못하는 데 세금이라도 아끼게 그냥 폐지해라..      혐오\n",
       "94190                                        재미가 없으니 망하지      혐오\n",
       "94191  공장 도시락 비우생적임 아르바이트했는데 화장실가성 손도 않씯고 재료 담고 바닥 떨어...      혐오\n",
       "94192               코딱지 만한 나라에서 지들끼리 피터지게 싸우는 센징 클래스 ㅉㅉㅉ      혐오\n",
       "94193               와이프도 그렇고 댓글 다 볼텐데 이휘재 좀 하차 하라고 전해주세요      혐오\n",
       "\n",
       "[94194 rows x 2 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"ai_hub_data.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AutoTokenizer\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"monologg/kobert\",\n",
    "    num_labels = 7\n",
    "    )\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"monologg/kobert\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(8002, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "data['Sentence'] = data[\"Sentence\"].apply(lambda x: re.sub(\"[^0-9a-zA-Z가-힣\\s+]\", \"\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# label 수치화\n",
    "def encoding(label):\n",
    "    if label == \"중립\":\n",
    "        return 0\n",
    "    elif label == \"놀람\":\n",
    "        return 1\n",
    "    elif label == \"분노\":\n",
    "        return 2\n",
    "    elif label == \"슬픔\":\n",
    "        return 3\n",
    "    elif label == \"행복\":\n",
    "        return 4\n",
    "    elif label == \"혐오\":\n",
    "        return 5\n",
    "    elif label == \"공포\":\n",
    "        return 6\n",
    "\n",
    "data['Emotion'] = data['Emotion'].apply(lambda x: encoding(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Emotion\n",
       "0    48616\n",
       "1    10764\n",
       "2     9293\n",
       "3     7239\n",
       "4     7067\n",
       "5     5649\n",
       "6     5566\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>손님 왔어요</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>손님 누구</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>몰라요 팀장님 친구래요</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>내 친구 친구 누구</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>그래서 무슨 일 해</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>그냥 방송일 조금</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>방송 방송 뭐</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>케이블 같은데서 아침에 배도 타고 산도 오르고 있어 그런 거</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>사는 덴 어디야</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>개포동</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>남편은 뭐하는데</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>언제부터 시작할 수 있어</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>에이 내가 무슨 나 못해</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>왜</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>나 이런 거 한번도 안 해봤어</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>야야 그러지말고 내가 이런 거 잘하는데 딴데 소개 시켜줄께 이런 거</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>이런 거 돈이 안된다 이거야 돈 제대로 줄께 걱정마</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>아니 그런 게 아니라</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>아니면 됐네</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>왜요</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Sentence  Emotion\n",
       "2                                  손님 왔어요        0\n",
       "3                                   손님 누구        0\n",
       "4                            몰라요 팀장님 친구래요        0\n",
       "5                              내 친구 친구 누구        0\n",
       "7                              그래서 무슨 일 해        0\n",
       "8                              그냥 방송일 조금         0\n",
       "9                                 방송 방송 뭐        0\n",
       "10      케이블 같은데서 아침에 배도 타고 산도 오르고 있어 그런 거        0\n",
       "11                               사는 덴 어디야        0\n",
       "12                                    개포동        0\n",
       "13                               남편은 뭐하는데        0\n",
       "15                          언제부터 시작할 수 있어        0\n",
       "20                          에이 내가 무슨 나 못해        0\n",
       "21                                      왜        0\n",
       "22                       나 이런 거 한번도 안 해봤어        0\n",
       "24  야야 그러지말고 내가 이런 거 잘하는데 딴데 소개 시켜줄께 이런 거        0\n",
       "25           이런 거 돈이 안된다 이거야 돈 제대로 줄께 걱정마        0\n",
       "26                            아니 그런 게 아니라        0\n",
       "27                                 아니면 됐네        0\n",
       "30                                     왜요        0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data[\"Emotion\"] == 0].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터셋 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainX: (75355,), TrainY: (75355,)\n",
      "TestX: (18839,), TestY: (18839,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "trainX, testX, trainY, testY = train_test_split(\n",
    "    data[\"Sentence\"],\n",
    "    data[\"Emotion\"],\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"TrainX: {trainX.shape}, TrainY: {trainY.shape}\")\n",
    "print(f\"TestX: {testX.shape}, TestY: {testY.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainX: (60284,), TrainY: (60284,)\n",
      "ValX: (15071,), ValY: (15071,)\n",
      "TestX: (18839,), TestY: (18839,)\n"
     ]
    }
   ],
   "source": [
    "trainX, valX, trainY, valY = train_test_split(\n",
    "    trainX, trainY, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"TrainX: {trainX.shape}, TrainY: {trainY.shape}\")\n",
    "print(f\"ValX: {valX.shape}, ValY: {valY.shape}\")\n",
    "print(f\"TestX: {testX.shape}, TestY: {testY.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 토크나이징 클래스화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        self.texts = texts.tolist() \n",
    "        self.labels = labels.tolist()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        encoded_output = self.tokenizer(\n",
    "            text, \n",
    "            max_length = self.max_length, # 모델이 처리할 수 있는 최대 토큰의 길이\n",
    "            padding=\"max_length\", # max_length 보다 짧을 경우 패딩 토큰을 추가하여 길이를 맞춘다\n",
    "            truncation=True, # max_length 보다 길경우 자른다\n",
    "            add_special_tokens=True, # bert 모델의 필요한 특수토큰을 자동으로 추가(?)\n",
    "            return_token_type_ids=True, # 텍스트를 변환해서 반환할거냐 ?\n",
    "            return_attention_mask=True, # 실제토큰 1 패딩토큰 0 반환\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return encoded_output\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 데이터 가져오기\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # 토크나이징\n",
    "        encoding = self.tokenize(text)\n",
    "\n",
    "        # 라벨 추가\n",
    "        # encoding[\"label\"] = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].flatten(),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].flatten(),\n",
    "            \"token_type_ids\": encoding[\"token_type_ids\"].flatten(),\n",
    "            \"label\": torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 128\n",
    "train_dataset = CustomDataset(trainX, trainY, tokenizer, max_length)\n",
    "val_dataset = CustomDataset(valX, valY, tokenizer, max_length)\n",
    "test_dataset = CustomDataset(testX, testY, tokenizer, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size = batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from transformers import AutoModel\n",
    "\n",
    "# class CustomKoBERT(nn.Module): # pyTorch의 nn.Module을 상속하여 클래스 정의\n",
    "#     def __init__(self, num_labels):\n",
    "#         super(CustomKoBERT, self).__init__()\n",
    "#         self.bert = AutoModel.from_pretrained(\"monologg/kobert\")\n",
    "#         self.classifier = nn.Linear(768, num_labels)  #분류 헤드 정의: BERT의 출력(768차원)을 입력으로, 분류할 클래스 개수만큼 출력생성하는 nn.linear정의\n",
    "#         self.loss_fn = nn.CrossEntropyLoss()  # 손실 함수 정의\n",
    "\n",
    "#     def forward(self, input_ids, attention_mask=None, token_type_ids=None, labels=None):\n",
    "#         # BERT 모델의 출력\n",
    "#         outputs = self.bert(input_ids=input_ids,\n",
    "#                             attention_mask=attention_mask,\n",
    "#                             token_type_ids=token_type_ids)\n",
    "#         pooled_output = outputs[1]  # KoBERT 의 두번째 값인 pooled_output을 가져옴 이것은? -> 문장의 전체의미를 요약한 벡터\n",
    "        \n",
    "#         # 분류 헤드 통과\n",
    "#         logits = self.classifier(pooled_output)  # 전체의미를요약한 벡터를 분류기에 넣어서 분류결과를 생성\n",
    "        \n",
    "#         # 손실 계산 (labels가 주어진 경우)\n",
    "#         loss = None\n",
    "#         if labels is not None:\n",
    "#             loss = self.loss_fn(logits, labels) # 예측값과 라벨과 손실 값을 계산\n",
    "\n",
    "#         return {\"loss\": loss, \"logits\": logits} # train 중에는 손실 값 사용 / 추론 시 불류 결과 사용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(8002, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:1\n",
      "Count of using GPUs: 1\n",
      "Current cuda device: 0\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "# device = f\"cuda:{1}\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# print('Device:', device)  # 출력결과: cuda \n",
    "# print('Count of using GPUs:', torch.cuda.device_count())   #출력결과: 2 (2, 3 두개 사용하므로)\n",
    "# print('Current cuda device:', torch.cuda.current_device())  # 출력결과: 2 (2, 3 중 앞의 GPU #2 의미)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, Train_loss: 1.2186526687750652, Validation_loss: 1.0501681754255443\n",
      "epoch: 2, Train_loss: 0.7964334391731311, Validation_loss: 1.0364219574912148\n",
      "epoch: 4, Train_loss: 0.4722095432171389, Validation_loss: 1.3115983276691174\n",
      "epoch: 6, Train_loss: 0.2667124072578842, Validation_loss: 1.6156558333644901\n",
      "epoch: 8, Train_loss: 0.1594816120932805, Validation_loss: 1.8473195127940638\n",
      "Total training time: 1346.22 seconds\n"
     ]
    }
   ],
   "source": [
    "# # 소요되는 시간 산정해보기\n",
    "\n",
    "# from torch.optim import AdamW\n",
    "# from transformers import get_linear_schedule_with_warmup\n",
    "# from torch.nn.utils import clip_grad_norm_\n",
    "# import torch\n",
    "# import time  # 시간 측정을 위한 모듈\n",
    "\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# # 하이퍼 파라미터 설정\n",
    "# epochs = 10\n",
    "# optimizer = AdamW(model.parameters(), lr=5e-5, weight_decay=0.01)\n",
    "\n",
    "# # 스케줄러 설정\n",
    "# total_steps = len(train_loader) * epochs\n",
    "# scheduler = get_linear_schedule_with_warmup(\n",
    "#     optimizer,\n",
    "#     num_warmup_steps=500,\n",
    "#     num_training_steps=total_steps\n",
    "# )\n",
    "\n",
    "# loss_history = {\"train\": [], \"validation\": []}\n",
    "# patience = 5\n",
    "# patience_cnt = 0\n",
    "# best_loss_val = float('inf')\n",
    "# model = model.to(device)\n",
    "\n",
    "# # epoch 전 시작시간 기록\n",
    "# start_time = time.time()\n",
    "\n",
    "# for epoch in range(epochs):\n",
    "#     #### Train ####\n",
    "#     model.train()\n",
    "\n",
    "#     loss_train = 0.0\n",
    "#     for batch in train_loader:\n",
    "#         # GPU 보내기\n",
    "#         input_ids = batch['input_ids'].to(device)\n",
    "#         attention_mask = batch['attention_mask'].to(device)\n",
    "#         token_type_ids = batch['token_type_ids'].to(device)\n",
    "#         labels = batch['label'].to(device)\n",
    "\n",
    "#         # 학습과정\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(\n",
    "#             input_ids=input_ids,\n",
    "#             attention_mask=attention_mask,\n",
    "#             token_type_ids=token_type_ids,\n",
    "#             labels=labels \n",
    "#         )\n",
    "#         loss = outputs.loss\n",
    "#         loss.backward()\n",
    "#         # 기울기 폭주 방지\n",
    "#         clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "#         optimizer.step()\n",
    "#         scheduler.step()\n",
    "\n",
    "#         # loss 저장\n",
    "#         loss_train += loss.item() * batch_size\n",
    "#     loss_history['train'].append(loss_train / len(train_dataset))\n",
    "\n",
    "#     #### Validation ####\n",
    "\n",
    "#     model.eval()\n",
    "\n",
    "#     loss_val = 0.0\n",
    "#     for batch in val_loader:\n",
    "#         # GPU 보내기\n",
    "#         input_ids = batch['input_ids'].to(device)\n",
    "#         attention_mask = batch['attention_mask'].to(device)\n",
    "#         token_type_ids = batch['token_type_ids'].to(device)\n",
    "#         labels = batch['label'].to(device)\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             outputs = model(\n",
    "#                 input_ids=input_ids,\n",
    "#                 attention_mask=attention_mask,\n",
    "#                 token_type_ids=token_type_ids,\n",
    "#                 labels=labels \n",
    "#             )\n",
    "#             loss = outputs.loss\n",
    "#         loss_val += loss.item() * batch_size\n",
    "#     loss_history['validation'].append(loss_val / len(val_dataset))\n",
    "\n",
    "#     #### Early Stopping ####\n",
    "#     if loss_val < best_loss_val:\n",
    "#         best_loss_val = loss_val\n",
    "#         torch.save(model.state_dict(), \"team1_test.pth\")\n",
    "#         patience_cnt += 1\n",
    "#         if patience_cnt == patience:\n",
    "#             print(\"Early stopping!\")\n",
    "#             break\n",
    "\n",
    "#     if epoch % 2 == 0:\n",
    "#         print(f\"epoch: {epoch}, Train_loss: {loss_train/len(train_dataset)}, Validation_loss: {loss_val / len(val_dataset)}\")\n",
    "\n",
    "# # 학습 종료 시간 기록 및 학습 시간 계산\n",
    "# end_time = time.time()\n",
    "# elapsed_time = end_time - start_time\n",
    "\n",
    "# # 학습 시간 출력 (초 단위로 출력)\n",
    "# print(f\"Total training time: {elapsed_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, Train_loss: 1.304146728378943, Validation_loss: 1.1097014402316503\n",
      "epoch: 2, Train_loss: 0.8928535645060767, Validation_loss: 1.020756829639997\n",
      "epoch: 4, Train_loss: 0.6916064365914202, Validation_loss: 1.0973090971088086\n",
      "epoch: 6, Train_loss: 0.5322882185791635, Validation_loss: 1.2097582168786656\n",
      "epoch: 8, Train_loss: 0.4261204054831636, Validation_loss: 1.3196048687214827\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "import torch\n",
    "import os\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# 하이퍼 파라미터 설정\n",
    "\n",
    "epochs = 10\n",
    "optimizer = AdamW(model.parameters(), lr = 2e-5, weight_decay=0.01) # 손실함수에 가중치 정형화 적용해보기 .. 일단 작게 0.01 만.. 언더피팅 안나게 ..\n",
    "\n",
    "# 스케줄러 설정\n",
    "# 워밍업 단계(학습률을 선형적으로 증가) / 학습 단계(학습률을 선형적으로 감소)\n",
    "total_steps = len(train_loader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps = 500,\n",
    "    num_training_steps = total_steps\n",
    ")\n",
    "\n",
    "loss_history = {\"train\" : [], \"validation\" : []}\n",
    "patience = 5\n",
    "patience_cnt = 0\n",
    "best_loss_val = float('inf')\n",
    "model = model.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    #### Train ####\n",
    "    model.train()\n",
    "\n",
    "    loss_train = 0.0\n",
    "    for batch in train_loader:\n",
    "        # GPU 보내기\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        token_type_ids = batch['token_type_ids'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        # 학습과정\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(\n",
    "            input_ids = input_ids,\n",
    "            attention_mask = attention_mask,\n",
    "            token_type_ids = token_type_ids,\n",
    "            labels = labels \n",
    "        )\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        # 기울기 폭주(exploration)\n",
    "        clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        # loss 저장\n",
    "        loss_train += loss.item() * batch_size\n",
    "    loss_history['train'].append(loss_train / len(train_dataset))\n",
    "\n",
    "    #### Validation ####\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    loss_val = 0.0\n",
    "    for batch in val_loader:\n",
    "        # GPU 보내기\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        token_type_ids = batch['token_type_ids'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(\n",
    "            input_ids = input_ids,\n",
    "            attention_mask = attention_mask,\n",
    "            token_type_ids = token_type_ids,\n",
    "            labels = labels \n",
    "            )\n",
    "            loss = outputs.loss\n",
    "        loss_val += loss.item() * batch_size\n",
    "    loss_history['validation'].append(loss_val / len(val_dataset))\n",
    "\n",
    "    #### Early Stopping ####\n",
    "    if loss_val < best_loss_val:\n",
    "        best_loss_val = loss_val\n",
    "        torch.save(model.state_dict(), \"REALtest.pth\")\n",
    "        patience_cnt += 1\n",
    "        if patience_cnt == patience:\n",
    "            print(\"Early stopping!\")\n",
    "            break\n",
    "\n",
    "    if epoch % 2 == 0 :\n",
    "        print(f\"epoch: {epoch}, Train_loss: {loss_train/len(train_dataset)}, Validation_loss: {loss_val / len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.optim import AdamW\n",
    "# from transformers import get_linear_schedule_with_warmup\n",
    "# from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "# # CustomKoBERT 모델 생성\n",
    "# num_labels = 7\n",
    "# batch_size = 8\n",
    "# epochs = 50\n",
    "# model = CustomKoBERT(num_labels=num_labels).to(device)\n",
    "\n",
    "# # Optimizer 및 스케줄러 설정 (변경 없음)\n",
    "# optimizer = AdamW(model.parameters(), lr=0.001)\n",
    "# total_steps = len(train_loader) * epochs\n",
    "# scheduler = get_linear_schedule_with_warmup(\n",
    "#     optimizer,\n",
    "#     num_warmup_steps=0,\n",
    "#     num_training_steps=total_steps\n",
    "# )\n",
    "# loss_history = {\"train\": [], \"validation\" : []}\n",
    "# patience = 7\n",
    "# patience_cnt = 0\n",
    "# best_loss_val = float('inf')\n",
    "\n",
    "# # 학습 루프 (변경 없음)\n",
    "# for epoch in range(epochs):\n",
    "#     model.train()\n",
    "#     loss_train = 0.0\n",
    "\n",
    "#     for batch in train_loader:\n",
    "#         input_ids = batch['input_ids'].to(device)\n",
    "#         attention_mask = batch['attention_mask'].to(device)\n",
    "#         token_type_ids = batch['token_type_ids'].to(device)\n",
    "#         labels = batch['label'].to(device)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "        \n",
    "#         # Forward pass (loss와 logits 반환)\n",
    "#         outputs = model(\n",
    "#             input_ids=input_ids,\n",
    "#             attention_mask=attention_mask,\n",
    "#             token_type_ids=token_type_ids,\n",
    "#             labels=labels\n",
    "#         )\n",
    "        \n",
    "#         loss = outputs[\"loss\"]\n",
    "#         loss.backward()\n",
    "\n",
    "#         clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "#         optimizer.step()\n",
    "#         scheduler.step()\n",
    "\n",
    "#         loss_train += loss.item() * batch_size\n",
    "\n",
    "#     loss_history['train'].append(loss_train / len(train_dataset))\n",
    "\n",
    "#     #### Validation ####\n",
    "#     model.eval()\n",
    "#     loss_val = 0.0\n",
    "\n",
    "#     for batch in val_loader:\n",
    "#         input_ids = batch['input_ids'].to(device)\n",
    "#         attention_mask = batch['attention_mask'].to(device)\n",
    "#         token_type_ids = batch['token_type_ids'].to(device)\n",
    "#         labels = batch['label'].to(device)\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             outputs = model(\n",
    "#                 input_ids=input_ids,\n",
    "#                 attention_mask=attention_mask,\n",
    "#                 token_type_ids=token_type_ids,\n",
    "#                 labels=labels\n",
    "#             )\n",
    "#             loss = outputs[\"loss\"]\n",
    "\n",
    "#         loss_val += loss.item() * batch_size\n",
    "\n",
    "#     loss_history['validation'].append(loss_val / len(val_dataset))\n",
    "\n",
    "#     #### Early Stopping ####\n",
    "#     if loss_val < best_loss_val:\n",
    "#         best_loss_val = loss_val\n",
    "#         torch.save(model.state_dict(), \"Bert_best_model.pth\")\n",
    "#         patience_cnt += 1\n",
    "#         if patience_cnt == patience:\n",
    "#             print(\"Early stopping!\")\n",
    "#             break\n",
    "\n",
    "#     print(f\"epoch: {epoch}, Train_loss: {loss_train/len(train_dataset)}, Validation_loss: {loss_val / len(val_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1762636/3637709931.py:5: UserWarning: No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "  plt.legend()\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rc('font', family='NanumGothic')\n",
    "\n",
    "plt.plot(loss_history['train'], label='Train Loss')\n",
    "plt.plot(loss_history['validation'], label='Validation Loss')\n",
    "plt.title('loss 비교')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtest_loader\u001b[49m:\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;66;03m# gpu 보내기\u001b[39;00m\n\u001b[1;32m     12\u001b[0m         input_ids \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     13\u001b[0m         attention_mask \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_loader' is not defined"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"monologg/kobert\", num_labels=7)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"monologg/kobert\")\n",
    "model.load_state_dict(torch.load(\"REALtest.pth\"))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#### Test ####\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "loss_test = 0.0\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        # gpu 보내기\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        token_type_ids = batch['token_type_ids'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        # print(input_ids)\n",
    "        # print(attention_mask)\n",
    "        # print(token_type_ids)\n",
    "\n",
    "        # 예측\n",
    "        outputs = model(\n",
    "        input_ids = input_ids,\n",
    "        attention_mask = attention_mask,\n",
    "        token_type_ids = token_type_ids,\n",
    "        labels = labels \n",
    "        )\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        preds = outputs.logits.argmax(dim=1)\n",
    "        correct += (labels == preds).sum()\n",
    "\n",
    "        # loss 저장\n",
    "        loss_test += loss.item() * batch_size\n",
    "print(f\"Test Loss: {loss_test / len(test_dataset)}, Accuracy: {correct / len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_1789392/285093464.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"REALtest.pth\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertForSequenceClassification, AutoTokenizer\n",
    "\n",
    "# 모델 및 토크나이저 로드\n",
    "model = BertForSequenceClassification.from_pretrained(\"monologg/kobert\", num_labels=7)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"monologg/kobert\")\n",
    "model.load_state_dict(torch.load(\"REALtest.pth\"))\n",
    "\n",
    "# 디바이스 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# 입력 텍스트 토큰화\n",
    "text = \"너무 막막하네\"\n",
    "encoded_input = tokenizer(text, return_tensors=\"pt\")\n",
    "encoded_input = {key: val.to(device) for key, val in encoded_input.items()}\n",
    "\n",
    "# 모델 호출 및 출력 처리\n",
    "outputs = model(**encoded_input)\n",
    "print(outputs.logits.argmax(dim=1).item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available devices  2\n",
      "Current cuda device  0\n",
      "NVIDIA GeForce RTX 4090\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print ('Available devices ', torch.cuda.device_count())\n",
    "print ('Current cuda device ', torch.cuda.current_device())\n",
    "print(torch.cuda.get_device_name(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project3_team1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
