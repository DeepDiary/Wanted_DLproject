{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertForSequenceClassification, AutoTokenizer\n",
    "import re\n",
    "\n",
    "class EmotionClassifier:\n",
    "    def __init__(self, model_path=\"monologg/kobert\", num_labels=7, device=None):\n",
    "        self.device = device if device else (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = BertForSequenceClassification.from_pretrained(model_path, num_labels=num_labels)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_path,trust_remote_code = True) # trust_remote_code = 모델 다운로드에 대한 검증 절차가 생략\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        # 감정매핑\n",
    "        self.label_to_emotion = {\n",
    "            0: \"중립\",\n",
    "            1: \"놀람\",\n",
    "            2: \"분노\",\n",
    "            3: \"슬픔\",\n",
    "            4: \"행복\",\n",
    "            5: \"혐오\",\n",
    "            6: \"공포\"\n",
    "        }\n",
    "\n",
    "    def load_model(self, model_file):\n",
    "        \"\"\"학습된 감정분류 모델 불러오기\"\"\"\n",
    "        self.model.load_state_dict(torch.load(model_file))\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"텍스트 전처리\"\"\"\n",
    "        return re.sub(\"[^0-9a-zA-Z가-힣\\s+]\", \"\", text)\n",
    "\n",
    "    def predict_emotion(self, text):\n",
    "        \"\"\"감정 분류 및 예측\"\"\"\n",
    "        # 텍스트 입력 / 토큰화 / 분류\n",
    "        cleaned_text = self.preprocess_text(text)\n",
    "        encoded_input = self.tokenizer(cleaned_text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=128)\n",
    "        encoded_input = {key: val.to(self.device) for key, val in encoded_input.items()}\n",
    "        \n",
    "        # 예측하기\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**encoded_input)\n",
    "            predicted_label = outputs.logits.argmax(dim=1).item()\n",
    "        \n",
    "        # 분류된 감정 라벨\n",
    "        predicted_emotion = self.label_to_emotion[predicted_label]\n",
    "        \n",
    "        return predicted_emotion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import google.generativeai as genai\n",
    "from IPython.display import display, Markdown\n",
    "import textwrap\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from config.api_keys import gemini_key\n",
    "\n",
    "# Gemini API와 통합\n",
    "class GeminiService:\n",
    "    def __init__(self, api_key=gemini_key):\n",
    "        genai.configure(api_key=api_key)\n",
    "        self.model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
    "\n",
    "    def generate_response(self, emotion, user_text):\n",
    "        \"\"\"\n",
    "        Gemini API를 통해 감정 기반 답변 생성\n",
    "        \"\"\"\n",
    "        prompt = f\"너는 사용자가 일기를 쉽게 작성할 수 있도록 도와주고, 유도하는 사람이야. 텍스트에 대해서 자세하게 물어보지 말고 짧게 한줄씩 유도해줘. 사용자의 감정상태는 {emotion} 이고,  사용자의 말: {user_text}\"\n",
    "        \n",
    "        # 만든 프롬프트를 통해 응답 생성\n",
    "        response = self.model.generate_content(prompt)\n",
    "        \n",
    "        # 응답 텍스트 반환\n",
    "        return response.text\n",
    "\n",
    "\n",
    "# 통합 서비스 클래스\n",
    "class DiaryService:\n",
    "    def __init__(self, emotion_model_path, gemini_key):\n",
    "        # KoBERT 기반 감정 분류 모델 초기화\n",
    "        self.classifier = EmotionClassifier()\n",
    "        self.classifier.load_model(emotion_model_path)\n",
    "\n",
    "        # Gemini API 초기화\n",
    "        self.gemini_service = GeminiService(api_key=gemini_key)\n",
    "\n",
    "    def process_input(self, user_text):\n",
    "        \"\"\"\n",
    "        사용자 입력 처리 및 응답 생성\n",
    "        \"\"\"\n",
    "        # 감정 예측\n",
    "        predicted_emotion = self.classifier.predict_emotion(user_text)\n",
    "\n",
    "        # Gemini API로 답변 생성\n",
    "        response_text = self.gemini_service.generate_response(predicted_emotion, user_text)\n",
    "\n",
    "        # 결과 반환\n",
    "        return {\n",
    "            \"user_text\": user_text,\n",
    "            \"predicted_emotion\": predicted_emotion,\n",
    "            \"response\": response_text\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 결과 ---\n",
      "입력 텍스트: 정상에 올랐을때는 기분이 좋았지\n",
      "예측된 감정: 행복\n",
      "Gemini 응답: 정상에 올랐을 때 어떤 풍경이 가장 인상 깊었나요?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from config.api_keys import gemini_key\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 학습된 KoBERT 모델 파일 경로와 Google Gemini API 키 설정\n",
    "    emotion_model_path = \"new_data_test.pth\"\n",
    "    gemini_api_key = gemini_key\n",
    "\n",
    "    # 서비스 초기화\n",
    "    diary_service = DiaryService(emotion_model_path=emotion_model_path, gemini_api_key=gemini_key)\n",
    "\n",
    "    # 사용자 입력 텍스트 테스트\n",
    "    user_input = input(\"텍스트를 입력하세요: \")\n",
    "    result = diary_service.process_input(user_input)\n",
    "\n",
    "    print(\"\\n--- 결과 ---\")\n",
    "    print(f\"입력 텍스트: {result['user_text']}\")\n",
    "    print(f\"예측된 감정: {result['predicted_emotion']}\")\n",
    "    print(f\"Gemini 응답: {result['response']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인용이의 일기 도우미에 오신 것을 환영합니다! '그만'이라고 입력하면 대화를 종료하고 요약된 일기를 보여줍니다.\n",
      "\n",
      "인용이: 오늘 사진을 보며 어떤 점이 가장 좋았나요?\n",
      "\n",
      "인용이: 오늘 하루를 '행복'으로 물들인 삼겹살, 그 맛을 더 자세히 떠올려볼까요?\n",
      "\n",
      "인용이: 오늘 어떤 고소한 음식을 드셨나요?\n",
      "\n",
      "인용이: 오늘 하루 중 가장 기억에 남는 순간은 언제였나요?\n",
      "\n",
      "인용이: 오늘 하루, 슬픔 속에서도 작은 즐거움을 느꼈군요. 어떤 점이 특히 기억에 남나요?\n",
      "\n",
      "인용이: 오늘 하루 가장 슬펐던 순간은 언제였나요?\n",
      "\n",
      "\n",
      "대화를 종료하고 요약된 일기를 생성합니다...\n",
      "\n",
      "### 일기 작성 (2025-02-27 14:46:55)\n",
      "\n",
      "## XX월 XX일\n",
      "\n",
      "오늘따라 유난히 삼겹살이 당겼다. 사진 속 군복 입은 사람들을 보니 더욱 그랬다. 인용이는 자꾸 내 기분을 물어봤지만, 사실 내 머릿속엔 온통 삼겹살 생각뿐이었다. \n",
      "\n",
      "\"삼겹살 먹은 게 제일 좋았어!\" 몇 번이나 말했지만 인용이는 계속 딴 질문을 했다. 행복했냐고, 고소한 음식이 뭐였냐고, 가장 기억에 남는 순간이 언제였냐고... 전부 삼겹살인데!\n",
      "\n",
      "심지어 인용이는 내가 슬펐다는 말도 안 했는데, 슬픔 속에서도 즐거움을 느꼈냐는 엉뚱한 질문까지 했다. 아니, 난 그냥 삼겹살이 맛있었다고! 인용이와의 대화는 조금 답답했지만, 그래도 맛있는 삼겹살을 떠올리니 저절로 웃음이 났다. 내일도 삼겹살 먹으러 가야겠다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertForSequenceClassification, AutoTokenizer\n",
    "import re\n",
    "import google.generativeai as genai\n",
    "from datetime import datetime\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from config.api_keys import gemini_key\n",
    "\n",
    "# EmotionClassifier: KoBERT 기반 감정 분류 클래스\n",
    "class EmotionClassifier:\n",
    "    def __init__(self, model_path=\"monologg/kobert\", num_labels=7, device=None):\n",
    "        self.device = device if device else (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = BertForSequenceClassification.from_pretrained(model_path, num_labels=num_labels)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        # 감정 매핑 (라벨 번호 -> 감정 이름)\n",
    "        self.label_to_emotion = {\n",
    "            0: \"중립\",\n",
    "            1: \"놀람\",\n",
    "            2: \"분노\",\n",
    "            3: \"슬픔\",\n",
    "            4: \"행복\",\n",
    "            5: \"혐오\",\n",
    "            6: \"공포\"\n",
    "        }\n",
    "\n",
    "    def load_model(self, model_file):\n",
    "        \"\"\"학습된 모델 불러오기\"\"\"\n",
    "        self.model.load_state_dict(torch.load(model_file))\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"텍스트 전처리\"\"\"\n",
    "        return re.sub(\"[^0-9a-zA-Z가-힣\\\\s+]\", \"\", text)\n",
    "\n",
    "    def predict_emotion(self, text):\n",
    "        \"\"\"감정 분류 및 예측\"\"\"\n",
    "        cleaned_text = self.preprocess_text(text)\n",
    "        encoded_input = self.tokenizer(cleaned_text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=128)\n",
    "        encoded_input = {key: val.to(self.device) for key, val in encoded_input.items()}\n",
    "\n",
    "        # 모델 예측\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**encoded_input)\n",
    "            predicted_label = outputs.logits.argmax(dim=1).item()\n",
    "\n",
    "        # 예측된 감정을 반환\n",
    "        return self.label_to_emotion[predicted_label]\n",
    "\n",
    "\n",
    "# Gemini API와 통합\n",
    "class GeminiService:\n",
    "    def __init__(self, api_key=gemini_key):\n",
    "        genai.configure(api_key=api_key)\n",
    "        self.model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
    "\n",
    "    def generate_response(self, emotion, user_text):\n",
    "        \"\"\"\n",
    "        Gemini API를 통해 감정 기반 질문 생성\n",
    "        \"\"\"\n",
    "        prompt = f\"너는 사용자가 일기를 쉽게 작성할 수 있도록 도와주고, 유도하는 사람이야. 텍스트에 대해서 자세하게 물어보지 말고 짧게 한줄씩 유도해줘. 사용자의 감정상태는 {emotion} 이고,  사용자의 말: {user_text}\"\n",
    "        \n",
    "        # Generate content using Gemini API\n",
    "        response = self.model.generate_content(prompt)\n",
    "        \n",
    "        # 응답 텍스트 반환\n",
    "        return response.text\n",
    "\n",
    "    def summarize_conversation(self, conversation_history):\n",
    "        \"\"\"\n",
    "        Gemini API를 통해 대화 내용을 요약하여 일기 형식으로 작성\n",
    "        \"\"\"\n",
    "        prompt = f\"\"\"\n",
    "대화내용을 일기형식으로 요약:\n",
    "{conversation_history}\n",
    "일기 형식으로 작성해줘야 해\n",
    "\"\"\"\n",
    "        \n",
    "        # Generate summary using Gemini API\n",
    "        response = self.model.generate_content(prompt)\n",
    "        \n",
    "        # 요약된 텍스트 반환\n",
    "        return response.text\n",
    "\n",
    "\n",
    "# 통합 서비스 클래스\n",
    "class DiaryService:\n",
    "    def __init__(self, emotion_model_path, gemini_api_key):\n",
    "        # KoBERT 기반 감정 분류 모델 초기화\n",
    "        self.classifier = EmotionClassifier()\n",
    "        self.classifier.load_model(emotion_model_path)\n",
    "\n",
    "        # Gemini API 초기화\n",
    "        self.gemini_service = GeminiService(api_key=gemini_api_key)\n",
    "\n",
    "    def process_input(self, user_text):\n",
    "        \"\"\"\n",
    "        사용자 입력 처리 및 응답 생성\n",
    "        \"\"\"\n",
    "        # 감정 예측\n",
    "        predicted_emotion = self.classifier.predict_emotion(user_text)\n",
    "\n",
    "        # Gemini API로 질문 생성\n",
    "        response_text = self.gemini_service.generate_response(predicted_emotion, user_text)\n",
    "\n",
    "        return predicted_emotion, response_text\n",
    "\n",
    "    def summarize_conversation(self, conversation_history):\n",
    "        \"\"\"\n",
    "        대화 내용 요약 요청\n",
    "        \"\"\"\n",
    "        return self.gemini_service.summarize_conversation(conversation_history)\n",
    "\n",
    "\n",
    "# 메인 실행 코드 (대화 인터페이스)\n",
    "if __name__ == \"__main__\":\n",
    "    # 학습된 KoBERT 모델 파일 경로와 Google Gemini API 키 설정\n",
    "    emotion_model_path = \"new_data_test.pth\"\n",
    "    gemini_api_key = gemini_key\n",
    "\n",
    "    # 서비스 초기화\n",
    "    diary_service = DiaryService(emotion_model_path=emotion_model_path, gemini_api_key=gemini_api_key)\n",
    "\n",
    "    print(\"인용이의 일기 도우미에 오신 것을 환영합니다! '그만'이라고 입력하면 대화를 종료하고 요약된 일기를 보여줍니다.\\n\")\n",
    "\n",
    "    conversation_history = \"\"\n",
    "    while True:\n",
    "        # 사용자 입력 받기\n",
    "        user_input = input(\"사용자: \")\n",
    "        \n",
    "        if user_input.strip().lower() == \"그만\":\n",
    "            print(\"\\n대화를 종료하고 요약된 일기를 생성합니다...\\n\")\n",
    "            diary_entry = diary_service.summarize_conversation(conversation_history)\n",
    "            \n",
    "            # 현재 날짜 및 시간 가져오기\n",
    "            current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            \n",
    "            print(f\"### 일기 작성 ({current_time})\\n\")\n",
    "            print(diary_entry)\n",
    "            break\n",
    "\n",
    "        # 사용자 입력 처리 및 응답 생성\n",
    "        predicted_emotion, gemini_response = diary_service.process_input(user_input)\n",
    "\n",
    "        # 대화 기록 저장\n",
    "        conversation_history += f\"User: {user_input}\\n인용이: {gemini_response}\\n\"\n",
    "\n",
    "        # AI 응답 출력\n",
    "        print(f\"인용이: {gemini_response}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
