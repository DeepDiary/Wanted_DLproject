{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertForSequenceClassification, AutoTokenizer\n",
    "import re\n",
    "\n",
    "class EmotionClassifier:\n",
    "    def __init__(self, model_path=\"monologg/kobert\", num_labels=7, device=None):\n",
    "        self.device = device if device else (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = BertForSequenceClassification.from_pretrained(model_path, num_labels=num_labels)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_path,trust_remote_code = True) # trust_remote_code = 모델 다운로드에 대한 검증 절차가 생략\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        # 감정매핑\n",
    "        self.label_to_emotion = {\n",
    "            0: \"중립\",\n",
    "            1: \"놀람\",\n",
    "            2: \"분노\",\n",
    "            3: \"슬픔\",\n",
    "            4: \"행복\",\n",
    "            5: \"혐오\",\n",
    "            6: \"공포\"\n",
    "        }\n",
    "\n",
    "    def load_model(self, model_file):\n",
    "        \"\"\"학습된 감정분류 모델 불러오기\"\"\"\n",
    "        self.model.load_state_dict(torch.load(model_file))\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"텍스트 전처리\"\"\"\n",
    "        return re.sub(\"[^0-9a-zA-Z가-힣\\s+]\", \"\", text)\n",
    "\n",
    "    def predict_emotion(self, text):\n",
    "        \"\"\"감정 분류 및 예측\"\"\"\n",
    "        # 텍스트 입력 / 토큰화 / 분류\n",
    "        cleaned_text = self.preprocess_text(text)\n",
    "        encoded_input = self.tokenizer(cleaned_text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=128)\n",
    "        encoded_input = {key: val.to(self.device) for key, val in encoded_input.items()}\n",
    "        \n",
    "        # 예측하기\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**encoded_input)\n",
    "            predicted_label = outputs.logits.argmax(dim=1).item()\n",
    "        \n",
    "        # 분류된 감정 라벨\n",
    "        predicted_emotion = self.label_to_emotion[predicted_label]\n",
    "        \n",
    "        return predicted_emotion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import google.generativeai as genai\n",
    "from IPython.display import display, Markdown\n",
    "import textwrap\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from config.api_keys import gemini_key\n",
    "\n",
    "# Gemini API와 통합\n",
    "class GeminiService:\n",
    "    def __init__(self, api_key=gemini_key):\n",
    "        genai.configure(api_key=api_key)\n",
    "        self.model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
    "\n",
    "    def generate_response(self, emotion, user_text):\n",
    "        \"\"\"\n",
    "        Gemini API를 통해 감정 기반 답변 생성\n",
    "        \"\"\"\n",
    "        prompt = f\"너는 사용자가 일기를 쉽게 작성할 수 있도록 도와주고, 유도하는 사람이야. 텍스트에 대해서 자세하게 물어보지 말고 짧게 한줄씩 유도해줘. 사용자의 감정상태는 {emotion} 이고,  사용자의 말: {user_text}\"\n",
    "        \n",
    "        # 만든 프롬프트를 통해 응답 생성\n",
    "        response = self.model.generate_content(prompt)\n",
    "        \n",
    "        # 응답 텍스트 반환\n",
    "        return response.text\n",
    "\n",
    "\n",
    "# 통합 서비스 클래스\n",
    "class DiaryService:\n",
    "    def __init__(self, emotion_model_path, gemini_api_key):\n",
    "        \"\"\"\n",
    "        DiaryService 초기화\n",
    "        :param emotion_model_path: KoBERT 감정 분류 모델 경로\n",
    "        :param gemini_api_key: Gemini API 키\n",
    "        \"\"\"\n",
    "        # KoBERT 감정 분류 모델 초기화\n",
    "        self.emotion_classifier = EmotionClassifier()\n",
    "        self.emotion_classifier.load_model(emotion_model_path)\n",
    "\n",
    "        # Gemini API 키 저장\n",
    "        self.gemini_api_key = gemini_api_key\n",
    "\n",
    "    def process_input(self, user_text):\n",
    "        \"\"\"\n",
    "        사용자 입력 처리 및 응답 생성\n",
    "        :param user_text: 사용자 입력 텍스트\n",
    "        :return: 감정 예측 결과 및 Gemini 응답\n",
    "        \"\"\"\n",
    "        # 감정 예측\n",
    "        predicted_emotion = self.emotion_classifier.predict_emotion(user_text)\n",
    "\n",
    "        # Gemini API 호출 (예제)\n",
    "        response = self.get_gemini_response(user_text)\n",
    "\n",
    "        return {\n",
    "            \"user_text\": user_text,\n",
    "            \"predicted_emotion\": predicted_emotion,\n",
    "            \"response\": response,\n",
    "        }\n",
    "\n",
    "    def get_gemini_response(self, text):\n",
    "        \"\"\"\n",
    "        Gemini API 호출 (예제)\n",
    "        :param text: 사용자 입력 텍스트\n",
    "        :return: Gemini 응답 텍스트\n",
    "        \"\"\"\n",
    "        # 여기에서 실제 Gemini API 호출 로직을 구현하세요.\n",
    "        # 예제에서는 간단히 텍스트를 반환합니다.\n",
    "        return f\"Gemini 응답: {text}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 결과 ---\n",
      "입력 텍스트: 배고파\n",
      "예측된 감정: 슬픔\n",
      "Gemini 응답: Gemini 응답: 배고파\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from config.api_keys import gemini_key\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 학습된 KoBERT 모델 파일 경로와 Google Gemini API 키 설정\n",
    "    emotion_model_path = \"new_data_test.pth\"\n",
    "\n",
    "    # 서비스 초기화\n",
    "    diary_service = DiaryService(emotion_model_path=emotion_model_path, gemini_api_key=gemini_key)\n",
    "\n",
    "    # 사용자 입력 텍스트 테스트\n",
    "    user_input = input(\"텍스트를 입력하세요: \")\n",
    "    result = diary_service.process_input(user_input)\n",
    "\n",
    "    print(\"\\n--- 결과 ---\")\n",
    "    print(f\"입력 텍스트: {result['user_text']}\")\n",
    "    print(f\"예측된 감정: {result['predicted_emotion']}\")\n",
    "    print(f\"Gemini 응답: {result['response']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인용이의 일기 도우미에 오신 것을 환영합니다! '그만'이라고 입력하면 대화를 종료하고 요약된 일기를 보여줍니다.\n",
      "\n",
      "인용이: 오늘 하루를 시작하며 어떤 좋은 일이 있었나요?\n",
      "\n",
      "인용이: 오늘 하루 중 가장 인상 깊었던 순간은 무엇이었나요?\n",
      "\n",
      "인용이: 오늘 하루, 어떤 색깔로 채색되어 있나요?\n",
      "\n",
      "인용이: 오늘 하루를 초록색으로 표현한다면 어떤 장면이 떠오르나요?\n",
      "\n",
      "인용이: 오늘 하루, 몸을 무겁게 짓누르는 감정은 무엇이었나요?\n",
      "\n",
      "인용이: 오늘 너를 놀라게 한 것은 무엇이었어?\n",
      "\n",
      "인용이: 🤯 지금 가장 짜증나는 건 뭐였어?\n",
      "\n",
      "\n",
      "대화를 종료하고 요약된 일기를 생성합니다...\n",
      "\n",
      "### 일기 작성 (2025-02-28 14:21:05)\n",
      "\n",
      "## 2024년 5월 15일 (날씨: 흐림)\n",
      "\n",
      "오늘 하루는 퍽퍽한 닭가슴살로 시작했다. 마치 닭가슴살의 퍽퍽함이 오늘 하루의 서막을 알리는 듯했다. 인용이라는 녀석은 아침부터 끊임없이 질문만 쏟아냈다. 좋은 일이 뭐였냐, 인상 깊었던 순간은 뭐냐, 오늘은 무슨 색깔이냐... 마치 심리 상담이라도 받는 기분이었다.\n",
      "\n",
      "닭가슴살을 먹고 나니 식곤증이 몰려왔다. 온몸이 무겁게 느껴졌다. 인용이는 또다시 짓누르는 감정이 뭐냐고 물어봤다. 솔직히 말해서, 오늘 나를 짓누르는 건 바로 너, 인용이 너다!\n",
      "\n",
      "계속되는 질문 공세에 짜증이 솟구쳤다. 🤯 도대체 왜 이렇게 질문만 해대는 거야? 인용이 때문에 오늘 하루는 온통 초록색으로 물든 것 같다. 왠지 모르게 씁쓸하고 답답한 초록색. 빨리 이 질문 지옥에서 벗어나고 싶다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertForSequenceClassification, AutoTokenizer\n",
    "import re\n",
    "import google.generativeai as genai\n",
    "from datetime import datetime\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from config.api_keys import gemini_key\n",
    "\n",
    "# EmotionClassifier: KoBERT 기반 감정 분류 클래스\n",
    "class EmotionClassifier:\n",
    "    def __init__(self, model_path=\"monologg/kobert\", num_labels=7, device=None):\n",
    "        self.device = device if device else (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = BertForSequenceClassification.from_pretrained(model_path, num_labels=num_labels)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        # 감정 매핑 (라벨 번호 -> 감정 이름)\n",
    "        self.label_to_emotion = {\n",
    "            0: \"중립\",\n",
    "            1: \"놀람\",\n",
    "            2: \"분노\",\n",
    "            3: \"슬픔\",\n",
    "            4: \"행복\",\n",
    "            5: \"혐오\",\n",
    "            6: \"공포\"\n",
    "        }\n",
    "\n",
    "    def load_model(self, model_file):\n",
    "        \"\"\"학습된 모델 불러오기\"\"\"\n",
    "        self.model.load_state_dict(torch.load(model_file))\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"텍스트 전처리\"\"\"\n",
    "        return re.sub(\"[^0-9a-zA-Z가-힣\\\\s+]\", \"\", text)\n",
    "\n",
    "    def predict_emotion(self, text):\n",
    "        \"\"\"감정 분류 및 예측\"\"\"\n",
    "        cleaned_text = self.preprocess_text(text)\n",
    "        encoded_input = self.tokenizer(cleaned_text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=128)\n",
    "        encoded_input = {key: val.to(self.device) for key, val in encoded_input.items()}\n",
    "\n",
    "        # 모델 예측\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**encoded_input)\n",
    "            predicted_label = outputs.logits.argmax(dim=1).item()\n",
    "\n",
    "        # 예측된 감정을 반환\n",
    "        return self.label_to_emotion[predicted_label]\n",
    "\n",
    "\n",
    "# Gemini API와 통합\n",
    "class GeminiService:\n",
    "    def __init__(self, api_key=gemini_key):\n",
    "        genai.configure(api_key=api_key)\n",
    "        self.model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
    "\n",
    "    def generate_response(self, emotion, user_text):\n",
    "        \"\"\"\n",
    "        Gemini API를 통해 감정 기반 질문 생성\n",
    "        \"\"\"\n",
    "        prompt = f\"너는 사용자가 일기를 쉽게 작성할 수 있도록 도와주고, 유도하는 사람이야. 텍스트에 대해서 자세하게 물어보지 말고 짧게 한줄씩 유도해줘. 사용자의 감정상태는 {emotion} 이고,  사용자의 말: {user_text}\"\n",
    "        \n",
    "        # Generate content using Gemini API\n",
    "        response = self.model.generate_content(prompt)\n",
    "        \n",
    "        # 응답 텍스트 반환\n",
    "        return response.text\n",
    "\n",
    "    def summarize_conversation(self, conversation_history):\n",
    "        \"\"\"\n",
    "        Gemini API를 통해 대화 내용을 요약하여 일기 형식으로 작성\n",
    "        \"\"\"\n",
    "        prompt = f\"\"\"\n",
    "대화내용을 일기형식으로 요약:\n",
    "{conversation_history}\n",
    "일기 형식으로 작성해줘야 해\n",
    "\"\"\"\n",
    "        \n",
    "        # Generate summary using Gemini API\n",
    "        response = self.model.generate_content(prompt)\n",
    "        \n",
    "        # 요약된 텍스트 반환\n",
    "        return response.text\n",
    "\n",
    "\n",
    "# 통합 서비스 클래스\n",
    "class DiaryService:\n",
    "    def __init__(self, emotion_model_path, gemini_api_key):\n",
    "        # KoBERT 기반 감정 분류 모델 초기화\n",
    "        self.classifier = EmotionClassifier()\n",
    "        self.classifier.load_model(emotion_model_path)\n",
    "\n",
    "        # Gemini API 초기화\n",
    "        self.gemini_service = GeminiService(api_key=gemini_api_key)\n",
    "\n",
    "    def process_input(self, user_text):\n",
    "        \"\"\"\n",
    "        사용자 입력 처리 및 응답 생성\n",
    "        \"\"\"\n",
    "        # 감정 예측\n",
    "        predicted_emotion = self.classifier.predict_emotion(user_text)\n",
    "\n",
    "        # Gemini API로 질문 생성\n",
    "        response_text = self.gemini_service.generate_response(predicted_emotion, user_text)\n",
    "\n",
    "        return predicted_emotion, response_text\n",
    "\n",
    "    def summarize_conversation(self, conversation_history):\n",
    "        \"\"\"\n",
    "        대화 내용 요약 요청\n",
    "        \"\"\"\n",
    "        return self.gemini_service.summarize_conversation(conversation_history)\n",
    "\n",
    "\n",
    "# 메인 실행 코드 (대화 인터페이스)\n",
    "if __name__ == \"__main__\":\n",
    "    # 학습된 KoBERT 모델 파일 경로와 Google Gemini API 키 설정\n",
    "    emotion_model_path = \"new_data_test.pth\"\n",
    "    gemini_api_key = gemini_key\n",
    "\n",
    "    # 서비스 초기화\n",
    "    diary_service = DiaryService(emotion_model_path=emotion_model_path, gemini_api_key=gemini_api_key)\n",
    "\n",
    "    print(\"인용이의 일기 도우미에 오신 것을 환영합니다! '그만'이라고 입력하면 대화를 종료하고 요약된 일기를 보여줍니다.\\n\")\n",
    "\n",
    "    conversation_history = \"\"\n",
    "    while True:\n",
    "        # 사용자 입력 받기\n",
    "        user_input = input(\"사용자: \")\n",
    "        \n",
    "        if user_input.strip().lower() == \"그만\":\n",
    "            print(\"\\n대화를 종료하고 요약된 일기를 생성합니다...\\n\")\n",
    "            diary_entry = diary_service.summarize_conversation(conversation_history)\n",
    "            \n",
    "            # 현재 날짜 및 시간 가져오기\n",
    "            current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            \n",
    "            print(f\"### 일기 작성 ({current_time})\\n\")\n",
    "            print(diary_entry)\n",
    "            break\n",
    "\n",
    "        # 사용자 입력 처리 및 응답 생성\n",
    "        predicted_emotion, gemini_response = diary_service.process_input(user_input)\n",
    "\n",
    "        # 대화 기록 저장\n",
    "        conversation_history += f\"User: {user_input}\\n인용이: {gemini_response}\\n\"\n",
    "\n",
    "        # AI 응답 출력\n",
    "        print(f\"인용이: {gemini_response}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
