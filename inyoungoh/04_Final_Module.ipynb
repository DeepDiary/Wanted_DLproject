{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertForSequenceClassification, AutoTokenizer\n",
    "import re\n",
    "\n",
    "class EmotionClassifier:\n",
    "    def __init__(self, model_path=\"monologg/kobert\", num_labels=7, device=None):\n",
    "        self.device = device if device else (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = BertForSequenceClassification.from_pretrained(model_path, num_labels=num_labels)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_path,trust_remote_code = True) # trust_remote_code = 모델 다운로드에 대한 검증 절차가 생략\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        # 감정매핑\n",
    "        self.label_to_emotion = {\n",
    "            0: \"중립\",\n",
    "            1: \"놀람\",\n",
    "            2: \"분노\",\n",
    "            3: \"슬픔\",\n",
    "            4: \"행복\",\n",
    "            5: \"혐오\",\n",
    "            6: \"공포\"\n",
    "        }\n",
    "\n",
    "    def load_model(self, model_file):\n",
    "        \"\"\"학습된 감정분류 모델 불러오기\"\"\"\n",
    "        self.model.load_state_dict(torch.load(model_file))\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"텍스트 전처리\"\"\"\n",
    "        return re.sub(\"[^0-9a-zA-Z가-힣\\s+]\", \"\", text)\n",
    "\n",
    "    def predict_emotion(self, text):\n",
    "        \"\"\"감정 분류 및 예측\"\"\"\n",
    "        # 텍스트 입력 / 토큰화 / 분류\n",
    "        cleaned_text = self.preprocess_text(text)\n",
    "        encoded_input = self.tokenizer(cleaned_text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=128)\n",
    "        encoded_input = {key: val.to(self.device) for key, val in encoded_input.items()}\n",
    "        \n",
    "        # 예측하기\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**encoded_input)\n",
    "            predicted_label = outputs.logits.argmax(dim=1).item()\n",
    "        \n",
    "        # 분류된 감정 라벨\n",
    "        predicted_emotion = self.label_to_emotion[predicted_label]\n",
    "        \n",
    "        return predicted_emotion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Emotion Label: 놀람\n"
     ]
    }
   ],
   "source": [
    "# 클래스 테스트 및 감정분류\n",
    "if __name__ == \"__main__\": # 직접 실행될때만 실행되게. 클래스를 불러와서 사용될때 같이 실행안되게\n",
    "    classifier = EmotionClassifier()\n",
    "    classifier.load_model(\"new_data_test.pth\")\n",
    "    sample_text = \"너 뭐하는 애야 ?\"\n",
    "    emotion_label = classifier.predict_emotion(sample_text)\n",
    "    print(f\"Predicted Emotion Label: {emotion_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
